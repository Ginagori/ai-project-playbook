"""
PRP Builder â€” Context-Aware Executable Specifications

Generates PRPs (Project Requirements Plans) that are specific to the project's
PRD, CLAUDE.md, tech stack, and feature requirements. Designed for agent-to-agent
communication: clear enough for Claude Code to execute without ambiguity.

No LLM calls â€” uses structured text parsing on the PRD and CLAUDE.md
(which are generated by the same system with predictable structure).
"""

import re

from agent.models.project import Feature, ProjectState, TechStack

# =============================================================================
# Markdown Parsing Helpers
# =============================================================================


def _parse_markdown_sections(content: str) -> dict[str, str]:
    """Parse markdown into a dict of {section_title: section_content}."""
    sections: dict[str, str] = {}
    current_title = ""
    current_lines: list[str] = []

    for line in content.split("\n"):
        header_match = re.match(r"^(#{1,3})\s+(.+)$", line)
        if header_match:
            if current_title:
                sections[current_title.lower().strip()] = "\n".join(current_lines).strip()
            current_title = header_match.group(2)
            current_lines = []
        else:
            current_lines.append(line)

    if current_title:
        sections[current_title.lower().strip()] = "\n".join(current_lines).strip()

    return sections


def _extract_bullet_points(text: str) -> list[str]:
    """Extract bullet point items from markdown text."""
    bullets = []
    for line in text.split("\n"):
        match = re.match(r"^\s*[-*]\s+(.+)$", line)
        if match:
            bullets.append(match.group(1).strip())
    return bullets


def _extract_numbered_items(text: str) -> list[str]:
    """Extract numbered list items from markdown text."""
    items = []
    for line in text.split("\n"):
        match = re.match(r"^\s*\d+\.\s+(.+)$", line)
        if match:
            items.append(match.group(1).strip())
    return items


def _extract_code_blocks(text: str) -> list[str]:
    """Extract fenced code blocks from markdown."""
    blocks = re.findall(r"```[\w]*\n(.*?)```", text, re.DOTALL)
    return [b.strip() for b in blocks]


def _extract_checkbox_items(text: str) -> list[str]:
    """Extract checkbox items (- [ ] ...) from markdown."""
    items = []
    for line in text.split("\n"):
        match = re.match(r"^\s*-\s+\[[ x]\]\s+(.+)$", line)
        if match:
            items.append(match.group(1).strip())
    return items


def _fuzzy_match(needle: str, haystack: str) -> bool:
    """Check if keywords from needle appear in haystack."""
    keywords = re.findall(r"\w{3,}", needle.lower())
    haystack_lower = haystack.lower()
    matches = sum(1 for kw in keywords if kw in haystack_lower)
    return matches >= max(1, len(keywords) // 2)


# =============================================================================
# Tech Stack Helpers
# =============================================================================


def _is_python_backend(tech_stack: TechStack) -> bool:
    """Detect if backend is Python-based."""
    backend = (tech_stack.backend or "").lower()
    return any(kw in backend for kw in ["python", "fastapi", "django", "flask"])


def _is_node_backend(tech_stack: TechStack) -> bool:
    """Detect if backend is Node-based."""
    backend = (tech_stack.backend or "").lower()
    return any(kw in backend for kw in ["node", "express", "nestjs", "serverless"])


def _is_react_frontend(tech_stack: TechStack) -> bool:
    """Detect if frontend is React-based."""
    frontend = (tech_stack.frontend or "").lower()
    return any(kw in frontend for kw in ["react", "next", "vite"])


def _is_vue_frontend(tech_stack: TechStack) -> bool:
    """Detect if frontend is Vue-based."""
    frontend = (tech_stack.frontend or "").lower()
    return any(kw in frontend for kw in ["vue", "nuxt"])


def _get_file_ext(tech_stack: TechStack) -> dict[str, str]:
    """Get file extensions based on tech stack."""
    is_python = _is_python_backend(tech_stack)
    return {
        "backend": ".py" if is_python else ".ts",
        "frontend": ".tsx"
        if _is_react_frontend(tech_stack)
        else ".vue"
        if _is_vue_frontend(tech_stack)
        else ".ts",
        "test_backend": ".py" if is_python else ".test.ts",
        "test_frontend": ".test.tsx" if _is_react_frontend(tech_stack) else ".test.ts",
        "config": "pyproject.toml" if is_python else "package.json",
    }


# =============================================================================
# Feature-to-Architecture Mapping
# =============================================================================

# Maps feature keywords to the architectural layers they touch
FEATURE_LAYER_MAP: dict[str, list[str]] = {
    "setup": ["config", "scripts"],
    "auth": ["models", "schemas", "services", "routes", "middleware", "tests"],
    "model": ["models", "schemas", "migrations", "repositories", "tests"],
    "data": ["models", "schemas", "migrations", "repositories", "tests"],
    "api": ["routes", "schemas", "middleware", "services", "tests"],
    "endpoint": ["routes", "schemas", "middleware", "services", "tests"],
    "dashboard": ["pages", "components", "hooks", "tests"],
    "frontend": ["pages", "components", "hooks", "styles", "tests"],
    "ui": ["pages", "components", "hooks", "styles", "tests"],
    "agent": ["agents", "tools", "memory", "config", "tests"],
    "plugin": ["plugins", "registry", "schemas", "tests"],
    "deploy": ["config", "scripts", "docker"],
    "test": ["tests"],
    "multi-tenant": ["middleware", "models", "migrations", "tests"],
    "real-time": ["websocket", "events", "handlers", "tests"],
    "memory": ["memory", "vectorstore", "config", "tests"],
    "tool": ["tools", "schemas", "tests"],
    "orchestrat": ["orchestrator", "agents", "state", "tests"],
    "communicat": ["messaging", "events", "handlers", "tests"],
}


def _get_feature_layers(feature: Feature) -> list[str]:
    """Determine which architectural layers a feature touches."""
    name_lower = feature.name.lower()
    desc_lower = feature.description.lower()
    combined = name_lower + " " + desc_lower

    layers: set[str] = set()
    for keyword, layer_list in FEATURE_LAYER_MAP.items():
        if keyword in combined:
            layers.update(layer_list)

    # Default layers if nothing matched
    if not layers:
        layers = {"services", "models", "routes", "tests"}

    return sorted(layers)


# =============================================================================
# PRPBuilder
# =============================================================================


class PRPBuilder:
    """
    Builds context-aware PRPs from project state.

    Takes the full ProjectState (including PRD and CLAUDE.md) and generates
    executable specifications that Claude Code can follow autonomously.
    """

    def __init__(self, project: ProjectState):
        self.project = project
        self.tech_stack = project.tech_stack
        self.is_python = _is_python_backend(project.tech_stack)
        self.is_react = _is_react_frontend(project.tech_stack)
        self.file_ext = _get_file_ext(project.tech_stack)

        # Parse PRD and CLAUDE.md into sections
        self.prd_sections = _parse_markdown_sections(project.prd or "")
        self.claude_md_sections = _parse_markdown_sections(project.claude_md or "")

        # Extract structured data from PRD
        self.prd_features = self._extract_prd_features()
        self.prd_success_criteria = self._extract_prd_success_criteria()

        # Extract structured data from CLAUDE.md
        self.architecture_pattern = self._extract_architecture_pattern()
        self.code_patterns = self._extract_code_patterns()

        # Cache lessons from MemoryBridge (queried once, used per-feature)
        self._cached_gotchas: list[str] = []
        self._cached_arch_lessons: list = []
        try:
            from agent.memory_bridge import MemoryBridge

            bridge = MemoryBridge.get_instance()
            tech_list = [
                t
                for t in [
                    self.tech_stack.frontend,
                    self.tech_stack.backend,
                    self.tech_stack.database,
                ]
                if t
            ]
            pt_value = project.project_type.value if project.project_type else "saas"

            self._cached_gotchas = bridge.get_gotchas(pt_value, tech_list)
            self._cached_arch_lessons = bridge.get_architecture_lessons(pt_value)
        except Exception:
            pass  # Backward compatible â€” no lessons available

    # -------------------------------------------------------------------------
    # PRD Parsing
    # -------------------------------------------------------------------------

    def _extract_prd_features(self) -> dict[str, list[str]]:
        """Extract feature requirements from PRD sections."""
        features: dict[str, list[str]] = {}

        # Look for MVP Scope / Core Features sections
        for key, content in self.prd_sections.items():
            if any(
                kw in key
                for kw in ["core features", "mvp scope", "features", "p0", "nice-to-have", "p1"]
            ):
                items = _extract_numbered_items(content) or _extract_bullet_points(content)
                for item in items:
                    # Use the first few words as the feature key
                    clean = re.sub(r"\*\*([^*]+)\*\*", r"\1", item)  # Remove bold
                    features[clean.lower()] = [item]

        return features

    def _extract_prd_success_criteria(self) -> list[str]:
        """Extract success criteria from PRD."""
        for key, content in self.prd_sections.items():
            if "success" in key and "criteria" in key:
                return _extract_checkbox_items(content) or _extract_bullet_points(content)
        return []

    def _find_requirements_for_feature(self, feature: Feature) -> list[str]:
        """Find PRD requirements relevant to a specific feature."""
        requirements: list[str] = []

        # Use pre-extracted feature requirements from PRD
        if feature.prd_requirements:
            return feature.prd_requirements

        # Search through PRD sections for feature mentions
        for key, content in self.prd_sections.items():
            if _fuzzy_match(feature.name, key) or _fuzzy_match(feature.name, content):
                items = _extract_bullet_points(content) + _extract_numbered_items(content)
                for item in items:
                    if _fuzzy_match(feature.name, item) or _fuzzy_match(feature.description, item):
                        requirements.append(item)

        # Also search in PRD feature list
        for prd_feature_key, items in self.prd_features.items():
            if _fuzzy_match(feature.name, prd_feature_key):
                requirements.extend(items)

        # Deduplicate
        seen: set[str] = set()
        unique: list[str] = []
        for r in requirements:
            if r not in seen:
                seen.add(r)
                unique.append(r)

        return unique or [feature.description]

    def _find_success_criteria_for_feature(self, feature: Feature) -> list[str]:
        """Find success criteria relevant to a specific feature."""
        if feature.success_criteria:
            return feature.success_criteria

        relevant = []
        for criterion in self.prd_success_criteria:
            if _fuzzy_match(feature.name, criterion) or _fuzzy_match(
                feature.description, criterion
            ):
                relevant.append(criterion)

        if not relevant:
            # Generate default criteria based on feature description
            relevant = [
                f"{feature.name} is fully functional with no TODOs",
                f"Unit tests pass for {feature.name}",
                "Integration with dependent features verified",
            ]

        return relevant

    # -------------------------------------------------------------------------
    # CLAUDE.md Parsing
    # -------------------------------------------------------------------------

    def _extract_architecture_pattern(self) -> str:
        """Extract architecture pattern from CLAUDE.md."""
        for key, content in self.claude_md_sections.items():
            if "architecture" in key.lower():
                return content
        return ""

    def _extract_code_patterns(self) -> list[str]:
        """Extract code pattern examples from CLAUDE.md."""
        for key, content in self.claude_md_sections.items():
            if "common patterns" in key.lower() or "patterns" in key.lower():
                return _extract_code_blocks(content)
        return []

    def _find_relevant_patterns(self, feature: Feature) -> str:
        """Find CLAUDE.md patterns relevant to a feature."""
        patterns: list[str] = []

        # Match architecture section
        if self.architecture_pattern:
            patterns.append(f"**Architecture:**\n{self.architecture_pattern}")

        # Match code patterns by feature type
        feature_lower = feature.name.lower() + " " + feature.description.lower()
        pattern_keywords = {
            "service": ["service", "business logic", "crud"],
            "api": ["api", "endpoint", "route", "handler"],
            "auth": ["auth", "login", "jwt", "token"],
            "agent": ["agent", "tool", "memory"],
            "plugin": ["plugin", "registry", "extension"],
            "supervisor": ["supervisor", "orchestrat", "coordinat"],
            "factory": ["factory", "registry", "pattern"],
        }

        for pattern_name, keywords in pattern_keywords.items():
            if any(kw in feature_lower for kw in keywords):
                # Find matching code blocks from CLAUDE.md
                for key, content in self.claude_md_sections.items():
                    if pattern_name in key.lower() or any(kw in key.lower() for kw in keywords):
                        code_blocks = _extract_code_blocks(content)
                        for block in code_blocks:
                            patterns.append(f"```\n{block}\n```")

        return "\n\n".join(patterns) if patterns else "Follow patterns defined in CLAUDE.md"

    # -------------------------------------------------------------------------
    # File Path Computation
    # -------------------------------------------------------------------------

    def _compute_file_paths(self, feature: Feature) -> dict[str, list[str]]:
        """Compute specific file paths based on tech stack, architecture, and feature."""
        layers = _get_feature_layers(feature)
        slug = feature.name.lower().replace(" ", "_").replace("-", "_")
        ext = self.file_ext
        paths: dict[str, list[str]] = {"create": [], "modify": []}

        # Backend files
        backend_layers = {
            "models",
            "schemas",
            "services",
            "routes",
            "middleware",
            "repositories",
            "migrations",
            "agents",
            "tools",
            "memory",
            "plugins",
            "registry",
            "orchestrator",
            "state",
            "messaging",
            "events",
            "handlers",
            "websocket",
            "vectorstore",
        }

        for layer in layers:
            if layer in backend_layers:
                if layer == "migrations":
                    paths["create"].append(f"migrations/{slug}_001{ext['backend']}")
                elif layer == "middleware":
                    paths["create"].append(f"src/middleware/{slug}{ext['backend']}")
                else:
                    paths["create"].append(f"src/{slug}/{layer}{ext['backend']}")

        # Frontend files
        frontend_layers = {"pages", "components", "hooks", "styles"}
        if any(layer in layers for layer in frontend_layers):
            component_name = feature.name.replace(" ", "")
            if "pages" in layers:
                paths["create"].append(f"src/pages/{component_name}{ext['frontend']}")
            if "components" in layers:
                paths["create"].append(f"src/components/{slug}/{component_name}{ext['frontend']}")
            if "hooks" in layers:
                hook_name = f"use{component_name}"
                paths["create"].append(f"src/hooks/{hook_name}{ext['frontend']}")

        # Test files
        if "tests" in layers:
            paths["create"].append(f"tests/{slug}/test_{slug}{ext['test_backend']}")
            if any(layer in layers for layer in frontend_layers):
                component_name = feature.name.replace(" ", "")
                paths["create"].append(
                    f"src/components/{slug}/{component_name}{ext['test_frontend']}"
                )

        # Config files
        if "config" in layers:
            paths["modify"].append(ext["config"])
            paths["create"].append(f"src/core/config{ext['backend']}")

        if "scripts" in layers:
            paths["create"].append("scripts/setup.sh")

        if "docker" in layers:
            paths["create"].append("Dockerfile")
            paths["create"].append("docker-compose.yml")

        return paths

    # -------------------------------------------------------------------------
    # Pseudocode Generation
    # -------------------------------------------------------------------------

    def _generate_pseudocode(self, feature: Feature, requirements: list[str]) -> str:
        """Generate tech-stack-specific pseudocode for a feature."""
        slug = feature.name.lower().replace(" ", "_").replace("-", "_")
        reqs_comments = "\n".join(f"    # - {r}" for r in requirements[:5])

        if self.is_python:
            return self._python_pseudocode(feature, slug, reqs_comments)
        else:
            return self._node_pseudocode(feature, slug, reqs_comments)

    def _python_pseudocode(self, feature: Feature, slug: str, reqs: str) -> str:
        """Generate Python/FastAPI pseudocode."""
        class_name = feature.name.replace(" ", "").replace("-", "")
        feature_lower = feature.name.lower()

        if "setup" in feature_lower:
            return f"""```python
# src/core/config.py
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    app_name: str = "{self.project.objective}"
    database_url: str
    jwt_secret: str
    debug: bool = False

    class Config:
        env_file = ".env"

settings = Settings()
```

```python
# src/main.py
from fastapi import FastAPI
from src.core.config import settings

app = FastAPI(title=settings.app_name)

# Register routers here as features are implemented
```"""

        if "auth" in feature_lower:
            return f"""```python
# src/auth/models.py
from sqlalchemy import Column, String, DateTime
from src.core.database import Base

class User(Base):
    __tablename__ = "users"
    id = Column(UUID, primary_key=True, default=uuid4)
    email = Column(String, unique=True, nullable=False)
    password_hash = Column(String, nullable=False)
    created_at = Column(DateTime, default=datetime.utcnow)
```

```python
# src/auth/service.py
from passlib.context import CryptContext

pwd_context = CryptContext(schemes=["bcrypt"])

class AuthService:
    def __init__(self, db: AsyncSession):
        self.db = db

    async def register(self, email: str, password: str) -> User:
        hashed = pwd_context.hash(password)
        user = User(email=email, password_hash=hashed)
        self.db.add(user)
        await self.db.commit()
        return user

    async def authenticate(self, email: str, password: str) -> User | None:
        user = await self.db.query(User).filter_by(email=email).first()
        if user and pwd_context.verify(password, user.password_hash):
            return user
        return None
```

```python
# src/auth/router.py
from fastapi import APIRouter, Depends, HTTPException
from src.auth.service import AuthService
from src.auth.schemas import SignupRequest, LoginRequest, TokenResponse

router = APIRouter(prefix="/auth", tags=["auth"])

@router.post("/signup", response_model=TokenResponse)
async def signup(data: SignupRequest, service: AuthService = Depends()):
    # Requirements from PRD:
{reqs}
    user = await service.register(data.email, data.password)
    token = create_access_token(user.id)
    return TokenResponse(access_token=token)
```"""

        # Generic Python feature
        return f"""```python
# src/{slug}/models.py
from pydantic import BaseModel
from uuid import UUID
from datetime import datetime

class {class_name}(BaseModel):
    id: UUID
    # Requirements from PRD:
{reqs}
    created_at: datetime
    updated_at: datetime
```

```python
# src/{slug}/service.py
from sqlalchemy.ext.asyncio import AsyncSession

class {class_name}Service:
    def __init__(self, db: AsyncSession):
        self.db = db

    async def create(self, data: {class_name}Create) -> {class_name}:
        # Implement creation logic
        pass

    async def get_by_id(self, id: str) -> {class_name} | None:
        # Implement retrieval logic
        pass

    async def list_all(self, limit: int = 50, offset: int = 0) -> list[{class_name}]:
        # Implement listing with pagination
        pass
```

```python
# src/{slug}/router.py
from fastapi import APIRouter, Depends, HTTPException, status
from src.{slug}.service import {class_name}Service
from src.{slug}.schemas import {class_name}Create, {class_name}Response

router = APIRouter(prefix="/{slug}", tags=["{slug}"])

@router.post("/", response_model={class_name}Response, status_code=status.HTTP_201_CREATED)
async def create_{slug}(data: {class_name}Create, service: {class_name}Service = Depends()):
    return await service.create(data)

@router.get("/{{item_id}}", response_model={class_name}Response)
async def get_{slug}(item_id: str, service: {class_name}Service = Depends()):
    result = await service.get_by_id(item_id)
    if not result:
        raise HTTPException(status_code=404, detail="{class_name} not found")
    return result
```"""

    def _node_pseudocode(self, feature: Feature, slug: str, reqs: str) -> str:
        """Generate Node/Express/TypeScript pseudocode."""
        class_name = feature.name.replace(" ", "").replace("-", "")
        feature_lower = feature.name.lower()

        if "setup" in feature_lower:
            return f"""```typescript
// src/config/index.ts
import dotenv from 'dotenv';
dotenv.config();

export const config = {{
  appName: '{self.project.objective}',
  port: parseInt(process.env.PORT || '3000'),
  databaseUrl: process.env.DATABASE_URL!,
  jwtSecret: process.env.JWT_SECRET!,
  nodeEnv: process.env.NODE_ENV || 'development',
}};
```

```typescript
// src/index.ts
import express from 'express';
import {{ config }} from './config';

const app = express();
app.use(express.json());

// Register routers here as features are implemented

app.listen(config.port, () => {{
  console.log(`${{config.appName}} running on port ${{config.port}}`);
}});
```"""

        if "auth" in feature_lower:
            return f"""```typescript
// src/auth/types.ts
export interface User {{
  id: string;
  email: string;
  passwordHash: string;
  createdAt: Date;
}}

export interface SignupRequest {{
  email: string;
  password: string;
}}

export interface TokenResponse {{
  accessToken: string;
  refreshToken: string;
}}
```

```typescript
// src/auth/service.ts
import bcrypt from 'bcryptjs';
import jwt from 'jsonwebtoken';
import {{ config }} from '../config';

export class AuthService {{
  async register(email: string, password: string): Promise<User> {{
    const passwordHash = await bcrypt.hash(password, 12);
    // Requirements from PRD:
{reqs}
    // Create user in database
    return user;
  }}

  async authenticate(email: string, password: string): Promise<string | null> {{
    const user = await this.findByEmail(email);
    if (!user || !await bcrypt.compare(password, user.passwordHash)) {{
      return null;
    }}
    return jwt.sign({{ userId: user.id }}, config.jwtSecret, {{ expiresIn: '24h' }});
  }}
}}
```"""

        # Generic Node feature
        return f"""```typescript
// src/{slug}/types.ts
export interface {class_name} {{
  id: string;
  // Requirements from PRD:
{reqs}
  createdAt: Date;
  updatedAt: Date;
}}

export interface {class_name}CreateRequest {{
  // Fill based on requirements above
}}
```

```typescript
// src/{slug}/service.ts
export class {class_name}Service {{
  async create(data: {class_name}CreateRequest): Promise<{class_name}> {{
    // Implement creation logic
  }}

  async getById(id: string): Promise<{class_name} | null> {{
    // Implement retrieval logic
  }}

  async list(limit = 50, offset = 0): Promise<{class_name}[]> {{
    // Implement listing with pagination
  }}
}}
```

```typescript
// src/{slug}/router.ts
import {{ Router }} from 'express';
import {{ {class_name}Service }} from './service';

const router = Router();
const service = new {class_name}Service();

router.post('/{slug}', async (req, res) => {{
  const result = await service.create(req.body);
  res.status(201).json(result);
}});

router.get('/{slug}/:id', async (req, res) => {{
  const result = await service.getById(req.params.id);
  if (!result) return res.status(404).json({{ error: '{class_name} not found' }});
  res.json(result);
}});

export {{ router as {slug}Router }};
```"""

    # -------------------------------------------------------------------------
    # Validation Commands
    # -------------------------------------------------------------------------

    def _build_validation_commands(self, feature: Feature) -> str:
        """Generate feature-specific validation commands."""
        slug = feature.name.lower().replace(" ", "_").replace("-", "_")

        if self.is_python:
            return f"""### Validation Loop

#### Level 1: Syntax & Style
```bash
ruff check src/{slug}/ --fix
ruff format src/{slug}/
```

#### Level 2: Type Safety
```bash
mypy src/{slug}/ --ignore-missing-imports
```

#### Level 3: Unit Tests
```bash
pytest tests/{slug}/ -v --tb=short
```

#### Level 4: Integration Tests
```bash
pytest tests/{slug}/ -v --tb=short -m integration
```

#### Level 5: Build Verification
```bash
python -c "from src.{slug} import router; print('Import OK')"
```"""
        else:
            return f"""### Validation Loop

#### Level 1: Syntax & Style
```bash
npx eslint src/{slug}/
npx prettier --check src/{slug}/
```

#### Level 2: Type Safety
```bash
npx tsc --noEmit
```

#### Level 3: Unit Tests
```bash
npx vitest run src/{slug}/
```

#### Level 4: Integration Tests
```bash
npx vitest run tests/integration/{slug}
```

#### Level 5: Build Verification
```bash
npm run build
```"""

    # -------------------------------------------------------------------------
    # Integration Points
    # -------------------------------------------------------------------------

    def _determine_integration_points(self, feature: Feature) -> str:
        """Determine what a feature connects to."""
        points: list[str] = []
        name_lower = feature.name.lower()

        # What this feature depends on
        if feature.depends_on:
            for dep in feature.depends_on:
                points.append(f"- **Depends on:** {dep}")

        # What depends on this feature
        dependents = [f.name for f in self.project.features if feature.name in f.depends_on]
        if dependents:
            points.append(f"- **Required by:** {', '.join(dependents)}")

        # Database connections
        if any(kw in name_lower for kw in ["model", "data", "auth", "multi-tenant"]):
            db = self.tech_stack.database or "database"
            points.append(f"- **Database:** {db} (read/write)")

        # Auth dependency
        if "auth" not in name_lower and any(
            kw in name_lower for kw in ["api", "endpoint", "dashboard", "admin"]
        ):
            points.append("- **Auth:** Requires authentication middleware")

        # API exposure
        if any(kw in name_lower for kw in ["api", "endpoint", "auth"]):
            points.append("- **Exposes:** REST API endpoints")

        # Frontend-backend connection
        if any(kw in name_lower for kw in ["dashboard", "frontend", "ui"]):
            points.append("- **Connects to:** Backend API via HTTP client")

        return "\n".join(points) if points else "- No external integration points"

    # -------------------------------------------------------------------------
    # Build PRP for a Single Feature
    # -------------------------------------------------------------------------

    def _build_codebase_context(self, feature: Feature) -> str:
        """Build Codebase Context subsection from CLAUDE.md + discovery_context."""
        lines = []

        if self.architecture_pattern:
            # Truncate to first 200 chars to keep concise
            arch_summary = self.architecture_pattern[:200].replace("\n", " ").strip()
            lines.append(f"- **Architecture:** {arch_summary}")

        if hasattr(self.project, "discovery_context") and self.project.discovery_context:
            domain = self.project.discovery_context.get("domain", "")
            if domain:
                lines.append(f"- **Domain:** {domain}")
            regulations = self.project.discovery_context.get("regulations", "")
            if regulations:
                lines.append(f"- **Regulatory:** {regulations}")

        if self._cached_arch_lessons:
            for lesson in self._cached_arch_lessons[:2]:
                lines.append(f"- **Learned:** {lesson.title} â€” {lesson.recommendation}")

        if not lines:
            lines.append("- Follow patterns defined in CLAUDE.md")

        return "\n".join(lines)

    def _build_gotchas_section(self, feature: Feature) -> str:
        """Build Known Gotchas from MemoryBridge + defaults."""
        gotchas = []

        # Project-specific gotchas from MemoryBridge
        if self._cached_gotchas:
            gotchas.extend(self._cached_gotchas[:3])

        # Baseline gotchas (always included)
        defaults = [
            "- Do NOT leave TODOs or placeholder code",
            "- Do NOT skip error handling at API boundaries",
            "- Do NOT hardcode configuration values (use environment variables)",
        ]
        gotchas.extend(d for d in defaults if d not in gotchas)

        return "\n".join(gotchas[:6])

    def _build_data_models_section(self, feature: Feature) -> str:
        """Build Data Models subsection for Implementation Blueprint."""
        class_name = feature.name.replace(" ", "").replace("-", "")

        if self.is_python:
            return f"""```python
class {class_name}(BaseModel):
    \"\"\"Data model for {feature.name}.\"\"\"
    id: UUID
    # Add fields based on PRD requirements
    created_at: datetime
    updated_at: datetime
```"""
        else:
            return f"""```typescript
interface {class_name} {{
  id: string;
  // Add fields based on PRD requirements
  createdAt: Date;
  updatedAt: Date;
}}
```"""

    def build_feature_prp(self, feature: Feature) -> str:
        """Build a complete PRP following the official template structure.

        Section order: Goal > Why > What > Success Criteria > Context
        (Must-Read Files, Codebase Context, Known Gotchas, Relevant Patterns)
        > Implementation Blueprint (Data Models, Tasks, Integration Points)
        > Validation Loop > Final Validation Checklist > Anti-Patterns.
        """
        requirements = self._find_requirements_for_feature(feature)
        criteria = self._find_success_criteria_for_feature(feature)
        file_paths = self._compute_file_paths(feature)
        pseudocode = self._generate_pseudocode(feature, requirements)
        validation = self._build_validation_commands(feature)
        integration = self._determine_integration_points(feature)
        patterns = self._find_relevant_patterns(feature)

        # New template-compliant sections
        codebase_context = self._build_codebase_context(feature)
        gotchas = self._build_gotchas_section(feature)
        data_models = self._build_data_models_section(feature)

        # Build helpers
        depends_str = ""
        if feature.depends_on:
            depends_str = f"\n**Depends on:** {', '.join(feature.depends_on)}\n"

        files_create = (
            "\n".join(f"- `{f}`" for f in file_paths["create"])
            or "- (determined during implementation)"
        )
        files_modify = (
            "\n".join(f"- `{f}`" for f in file_paths["modify"]) if file_paths["modify"] else ""
        )
        reqs_list = "\n".join(f"- {r}" for r in requirements)
        criteria_list = "\n".join(f"- [ ] {c}" for c in criteria)
        task_files = (
            ", ".join(f"`{f}`" for f in file_paths["create"][:3]) or "(see Files to Create)"
        )

        prp = f"""# PRP: {feature.name}

## Goal
{feature.description}
{depends_str}
## Why
Required for the project: {self.project.objective}. Priority: **{feature.priority.upper()}**.

## What
{reqs_list}

## Success Criteria
{criteria_list}

## Context

### Must-Read Files
{files_modify}
- `CLAUDE.md` â€” Project rules, architecture pattern, code style
- `docs/PRD.md` â€” Full product requirements

### Codebase Context
{codebase_context}

### Known Gotchas
{gotchas}

### Relevant Patterns
{patterns}

## Implementation Blueprint

### Data Models
{data_models}

### Tasks

#### Task 1: Implement {feature.name}
**Files:** {task_files}
**Pseudocode:**
{pseudocode}

### Files to Create
{files_create}

### Files to Modify
{files_modify if files_modify else "- (none for this feature)"}

### Integration Points
{integration}

{validation}

## Final Validation Checklist
- [ ] All tasks completed (no TODOs in code)
- [ ] All validation levels pass (syntax, types, unit, integration, build)
- [ ] Integration points tested with dependent features
- [ ] Error paths covered (not just happy path)
- [ ] {feature.name} is fully functional end-to-end

## Anti-Patterns
- Do NOT leave placeholder code or TODOs
- Do NOT skip tests for "simple" features
- Do NOT hardcode configuration values
- Do NOT commit secrets or environment variables
- Do NOT ignore type safety for "speed"
- Do NOT create files outside the defined architecture structure
"""
        return prp

    # -------------------------------------------------------------------------
    # Build Execution Package
    # -------------------------------------------------------------------------

    def build_execution_package(self) -> str:
        """Build the complete execution package for autonomous implementation."""
        project = self.project

        # Build dependency graph
        dep_graph = self._build_dependency_graph()

        # Order features by dependencies
        ordered_features = self._topological_sort_features()

        # Build all PRPs
        feature_prps = []
        for i, feature in enumerate(ordered_features, 1):
            prp = self.build_feature_prp(feature)
            checkpoint = self._build_checkpoint(i, feature, len(ordered_features))
            feature_prps.append(
                f"---\n\n## Feature {i} of {len(ordered_features)}: {feature.name}\n\n{prp}\n\n{checkpoint}"
            )

        features_section = "\n\n".join(feature_prps)

        # Build final validation
        final_validation = self._build_final_validation()

        package = f"""# Execution Package: {project.objective}

> **Generated by AI Project Playbook â€” Nivanta AI**
> **Project Type:** {project.project_type.value if project.project_type else "N/A"}
> **Scale:** {project.scale.value}
> **Features:** {len(ordered_features)}

---

## Instructions for Claude Code

Read this ENTIRE document before starting implementation.

**Execution Protocol:**
1. Read Section 1 (Project Rules) to understand conventions and architecture
2. Read Section 2 (Requirements) to understand what to build
3. Implement features IN ORDER (Section 3) â€” dependencies are already resolved
4. After EACH feature, run the Validation Loop commands
5. At each CHECKPOINT, report results and wait for human approval
6. After all features, run Final Validation (Section 4)

**Rules:**
- Follow CLAUDE.md patterns exactly â€” do not invent new patterns
- No TODOs, no placeholder code, no "implement later" comments
- Every feature must have tests before moving to the next
- If a validation step fails, fix it before proceeding
- Use conventional commits: feat:, fix:, test:, docs:

---

## Section 1: Project Rules

```markdown
{project.claude_md or "CLAUDE.md not generated yet. Complete the Planning phase first."}
```

---

## Section 2: Requirements

```markdown
{project.prd or "PRD not generated yet. Complete the Planning phase first."}
```

---

## Section 3: Implementation Roadmap

### Dependency Graph
{dep_graph}

{features_section}

---

## Section 4: Final Validation

{final_validation}

---

## Delivery Checklist

- [ ] All features implemented (no TODOs in codebase)
- [ ] All validation loops pass (lint, types, tests, build)
- [ ] API documentation generated (OpenAPI/Swagger)
- [ ] Environment variables documented in .env.example
- [ ] README.md with setup instructions
- [ ] Git history clean with conventional commits
"""
        return package

    # -------------------------------------------------------------------------
    # Execution Package Helpers
    # -------------------------------------------------------------------------

    def _build_dependency_graph(self) -> str:
        """Build a text representation of the dependency graph."""
        lines = []
        for feature in self.project.features:
            deps = (
                f" (depends on: {', '.join(feature.depends_on)})"
                if feature.depends_on
                else " (no dependencies)"
            )
            status_icon = {
                "pending": "â¬œ",
                "in_progress": "ðŸ”„",
                "completed": "âœ…",
                "blocked": "ðŸš«",
            }.get(feature.status, "â¬œ")
            lines.append(f"{status_icon} **{feature.name}**{deps}")
        return "\n".join(lines)

    def _topological_sort_features(self) -> list[Feature]:
        """Sort features respecting dependency order."""
        features = list(self.project.features)
        name_to_feature = {f.name: f for f in features}
        sorted_features: list[Feature] = []
        visited: set[str] = set()

        def visit(feature: Feature) -> None:
            if feature.name in visited:
                return
            visited.add(feature.name)
            for dep_name in feature.depends_on:
                if dep_name in name_to_feature:
                    visit(name_to_feature[dep_name])
            sorted_features.append(feature)

        for f in features:
            visit(f)

        return sorted_features

    def _build_checkpoint(self, index: int, feature: Feature, total: int) -> str:
        """Build a checkpoint section after a feature."""
        return f"""### CHECKPOINT {index}/{total}: {feature.name}

Before proceeding to the next feature, verify:
- [ ] All files listed in "Files to Create" exist
- [ ] All validation loop levels pass
- [ ] No TODOs or placeholder code remain
- [ ] Integration points with previous features work

**Human review required.** Report status and wait for "approved" to continue.
"""

    def _build_final_validation(self) -> str:
        """Build the final project validation section."""
        if self.is_python:
            return """### Full Project Validation

```bash
# 1. Lint entire project
ruff check src/ --fix
ruff format src/

# 2. Type check
mypy src/ --ignore-missing-imports

# 3. Run all tests
pytest tests/ -v --tb=short --cov=src --cov-report=term-missing

# 4. Check coverage
pytest --cov=src --cov-fail-under=80

# 5. Build verification
python -c "from src.main import app; print('Build OK')"

# 6. Security check
pip-audit
```"""
        else:
            return """### Full Project Validation

```bash
# 1. Lint entire project
npm run lint
npx prettier --check src/

# 2. Type check
npx tsc --noEmit

# 3. Run all tests
npm test -- --coverage

# 4. Check coverage
npx vitest run --coverage --coverage.thresholds.lines=80

# 5. Build verification
npm run build

# 6. Security check
npm audit
```"""


# =============================================================================
# Feature Enrichment (used by roadmap_node)
# =============================================================================


def enrich_features_from_prd(
    features: list[Feature],
    prd: str,
    project_type: str | None = None,
) -> list[Feature]:
    """
    Enrich feature objects with requirements extracted from the PRD.

    Called by roadmap_node() after creating the base feature list.
    """
    prd_sections = _parse_markdown_sections(prd)

    for feature in features:
        # Extract requirements
        for key, content in prd_sections.items():
            if _fuzzy_match(feature.name, content):
                items = _extract_bullet_points(content) + _extract_numbered_items(content)
                for item in items:
                    if _fuzzy_match(feature.name, item) or _fuzzy_match(feature.description, item):
                        if item not in feature.prd_requirements:
                            feature.prd_requirements.append(item)

        # Extract success criteria
        for key, content in prd_sections.items():
            if "success" in key:
                criteria = _extract_checkbox_items(content)
                for c in criteria:
                    if _fuzzy_match(feature.name, c) or _fuzzy_match(feature.description, c):
                        if c not in feature.success_criteria:
                            feature.success_criteria.append(c)

    # Compute dependencies based on logical ordering
    _compute_feature_dependencies(features)

    return features


def _compute_feature_dependencies(features: list[Feature]) -> None:
    """Compute feature dependencies based on logical ordering."""
    feature_names = [f.name for f in features]

    # Dependency rules based on feature type keywords
    dependency_rules: dict[str, list[str]] = {
        "auth": ["setup", "project setup"],
        "model": ["setup", "project setup"],
        "data": ["setup", "project setup"],
        "core data": ["setup", "project setup"],
        "multi-tenant": ["setup", "project setup", "auth"],
        "api": ["setup", "project setup", "model", "core data", "auth"],
        "endpoint": ["setup", "project setup", "model", "core data"],
        "dashboard": ["setup", "project setup", "api", "auth", "frontend"],
        "frontend": ["setup", "project setup", "api"],
        "agent core": ["setup", "project setup"],
        "tools": ["agent core", "setup"],
        "memory": ["agent core", "setup"],
        "orchestrat": ["agent", "setup", "project setup"],
        "communicat": ["agent", "orchestrat", "setup"],
        "plugin": ["setup", "project setup", "model", "core data"],
        "registry": ["setup", "project setup"],
        "real-time": ["setup", "project setup", "api", "auth"],
        "deploy": [],  # No dependencies computed, depends on everything
        "test": ["setup", "project setup"],
    }

    for feature in features:
        name_lower = feature.name.lower()
        deps: set[str] = set()

        for keyword, dep_keywords in dependency_rules.items():
            if keyword in name_lower:
                for dep_kw in dep_keywords:
                    # Find matching feature by keyword
                    for fname in feature_names:
                        if dep_kw in fname.lower() and fname != feature.name:
                            deps.add(fname)

        feature.depends_on = sorted(deps)
