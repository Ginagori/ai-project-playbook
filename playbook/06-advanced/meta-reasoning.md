# Meta-Reasoning - Detectar Scope Creep

**CÃ³mo detectar y prevenir scope creep en AI-generated plans**

---

## ðŸŽ¯ Concepto

**Meta-reasoning = Razonar sobre el razonamiento**

La AI puede generar plans muy largos sin darse cuenta de scope creep. TÃº necesitas detectarlo ANTES de implementar.

---

## ðŸš¨ Warning Signals

### Signal #1: Plan Length

**Regla de oro:**
- **200-400 lÃ­neas:** Feature bien scoped âœ…
- **400-800 lÃ­neas:** Feature complejo pero manejable âš ï¸
- **800-1,500 lÃ­neas:** Scope creep probable ðŸš¨
- **1,500+ lÃ­neas:** STOP - Scope creep confirmed ðŸ›‘

**Ejemplo del curso (MÃ³dulo 5):**
- Plan inicial: 1,700 lÃ­neas ðŸš¨
- DespuÃ©s de meta-reasoning: Dividir en 3 features

### Signal #2: NÃºmero de Files

**Healthy feature:**
- 3-8 archivos modificados âœ…

**Scope creep:**
- 15+ archivos modificados ðŸš¨
- Tocando 3+ carpetas diferentes ðŸš¨

### Signal #3: Dependencias No Planeadas

**Red flag:**
Plan dice "Also need to refactor X, update Y, migrate Z"

**SoluciÃ³n:**
Separate features:
- Feature A: Original request
- Feature B: Refactor X (separate PR)
- Feature C: Migrate Z (separate PR)

---

## ðŸ” Meta-Reasoning Process

### Step 1: Generate Initial Plan

```
Prompt: "Create plan to add email notifications"

Claude generates 1,200 line plan including:
- Email service setup
- Template system
- Queue system
- Analytics tracking
- Admin dashboard for emails
```

### Step 2: Meta-Reasoning Check

**Prompt:**
```
Before implementing, analyze this plan:

1. How many files will be modified?
2. How many new dependencies?
3. Does this touch multiple domains? (auth, billing, etc.)
4. Can this be split into smaller features?
5. What's the MINIMUM implementation?

Be brutally honest. If scope is too large, suggest split.
```

**Claude output:**
```
Analysis:
- Files: 23 (ðŸš¨ Too many)
- Dependencies: 4 new packages
- Domains: Email, Queue, Analytics, Admin UI
- **Recommendation: SPLIT**

Suggested approach:
1. Phase 1: Basic email sending (SendGrid integration only)
   - 4 files, 1 dependency, 200 lines
   - Delivers core value

2. Phase 2: Template system (separate PR)
   - 6 files, 300 lines

3. Phase 3: Analytics (separate PR)
   - 8 files, 400 lines
```

### Step 3: Approve Minimal Scope

```
Prompt: "Implement Phase 1 only. Create plan for basic email sending."

Claude generates 250-line focused plan âœ…
```

---

## ðŸ› ï¸ Research-First Approach

**Anti-pattern:**
```
User: "Add AI chat"
Claude: Immediately generates massive plan
```

**Better pattern:**
```
User: "Add AI chat"

Claude: "Before planning, let me research:
1. What chat libraries do we already use?
2. What AI provider do you prefer?
3. Do you have existing message storage?
4. What's the MVP feature set?"

[Research phase: 10 minutes]

Claude: "Based on research, I recommend:
- Use existing WebSocket setup
- OpenAI API (you already have key)
- Store in current messages table
- MVP: Text chat only (no files/images yet)

This is 300-line implementation. Want me to proceed?"
```

**Key:** Research reduces unknowns â†’ Better scoped plans

---

## ðŸ“Š Plan Quality Metrics

**High-quality plan indicators:**
- **Focused:** Single responsibility
- **Testable:** Clear validation steps
- **Incremental:** Can be deployed independently
- **Reversible:** Easy to rollback

**Low-quality plan (scope creep):**
- **Sprawling:** Touches unrelated systems
- **Vague:** "Also improve performance"
- **All-or-nothing:** Can't deploy partially
- **Risky:** Massive changes without safety net

---

## ðŸŽ¯ Ejemplo Real (Curso MÃ³dulo 5)

### Paddy Obsidian Agent

**Initial scope:** AI agent for Obsidian notes

**Plan length:** 1,700 lines ðŸš¨

**Meta-reasoning question:**
"Is this plan too large? Should we split it?"

**Answer:**
YES. Split into:
1. Core agent (query vault) - 500 lines
2. Advanced features (note creation) - 600 lines
3. UI improvements - 400 lines

**Result:**
3 separate PRs instead of 1 massive change âœ…

---

## ðŸ”„ Meta-Reasoning Prompts

### Prompt 1: Scope Check
```
Analyze this plan. Is scope appropriate for single PR?

Count:
- Files modified
- New dependencies
- Domains touched

If >10 files or >800 lines, suggest split.
```

### Prompt 2: MVP Definition
```
What's the MINIMUM implementation that delivers value?

Exclude:
- "Nice to have" features
- Future optimizations
- Polish/UX improvements

Focus on core functionality only.
```

### Prompt 3: Research Gaps
```
Before implementing, what do we need to research?

List unknowns:
- Existing code we should leverage
- Libraries/patterns already in use
- Database schema constraints
- API limitations

Let's research these BEFORE planning.
```

---

## ðŸŽ“ Key Takeaways

1. **Plan length = Scope indicator** - >800 lines = probable creep
2. **Meta-reasoning BEFORE implementing** - Saves weeks of work
3. **Research-first approach** - Reduces unknowns, better plans
4. **Split large features** - Multiple small PRs > 1 massive PR
5. **MVP mindset** - What's MINIMUM to deliver value?

---

**Rule of thumb:** If plan feels overwhelming, it probably is. Meta-reason before coding.
